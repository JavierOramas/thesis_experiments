{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # dataframe manipulation\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# sklearn \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import PowerTransformer, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, accuracy_score, classification_report\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "import lightgbm as lgb\n",
    "import prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Define a function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    \n",
    "    for i,sentence in enumerate(sentences):\n",
    "        sentence = sentence.split(\"|\")[-1]\n",
    "        sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "        sentences[i] = sentence.split(\"|\")[-1]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Load the dataset from a folder\n",
    "dataset_folder = \"documents/topic_model_dataset\"\n",
    "sentences = []\n",
    "\n",
    "# Iterate over files in the dataset folder\n",
    "for filename in os.listdir(dataset_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(dataset_folder, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            sentences.extend(preprocess_text(text))\n",
    "\n",
    "\n",
    "\n",
    "print(f'length of documents: {len(sentences)}')\n",
    "print(f\"first sentences:\\n\", \"\\n\".join(sentences[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.embeddings.basic_embeddings import Embedding\n",
    "import pandas as pd\n",
    "\n",
    "model = Embedding().get_llm()\n",
    "\n",
    "output = model.encode(sentences=sentences,\n",
    "         show_progress_bar=True,\n",
    "         normalize_embeddings=True)\n",
    "\n",
    "df_embedding = pd.DataFrame(output)\n",
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/DATA/THESIS/playground/kmeans_test.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/DATA/THESIS/playground/kmeans_test.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyod\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mecod\u001b[39;00m \u001b[39mimport\u001b[39;00m ECOD\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/DATA/THESIS/playground/kmeans_test.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf \u001b[39m=\u001b[39m ECOD()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/DATA/THESIS/playground/kmeans_test.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(df_embedding)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/DATA/THESIS/playground/kmeans_test.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m out \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(df_embedding) \n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/DATA/THESIS/playground/kmeans_test.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df_embedding[\u001b[39m\"\u001b[39m\u001b[39moutliers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m out\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "\n",
    "clf = ECOD()\n",
    "clf.fit(df_embedding)\n",
    "\n",
    "\n",
    "out = clf.predict(df_embedding) \n",
    "df_embedding[\"outliers\"] = out\n",
    "\n",
    "# df[\"outliers\"] = out\n",
    "\n",
    "df_embedding_no_out = df_embedding[df_embedding[\"outliers\"] == 0]\n",
    "df_embedding_no_out = df_embedding_no_out.drop([\"outliers\"], axis = 1)\n",
    "\n",
    "\n",
    "df_embedding_with_out = df_embedding.copy()\n",
    "df_embedding_with_out = df_embedding_with_out.drop([\"outliers\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_no_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "km = KMeans(init=\"k-means++\", random_state=0, n_init=\"auto\")\n",
    "visualizer = KElbowVisualizer(km, k=(15,15), locate_elbow=True)\n",
    " \n",
    "visualizer.fit(df_embedding_with_out)        # Fit the data to the visualizer\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_k = 15\n",
    "visualizer.elbow_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=n_k, init = \"k-means++\").fit(df_embedding_no_out)\n",
    "print(clusters.inertia_)\n",
    "clusters_predict = clusters.predict(df_embedding_no_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path_or_repo_id=\"/mnt/DATA/THESIS/playground/models/mistral-7b-instruct-v0.1.Q5_K_M.gguf\",\n",
    "    model_file=\"./models/mistral-7b-instruct-v0.1.Q5_K_M.gguf\",\n",
    "    model_type=\"mistral\", \n",
    "    gpu_layers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in zip(sentences,clusters_predict):\n",
    "#     print(i)\n",
    "\n",
    "data = pd.DataFrame(columns=[\"sentences\", \"topic\"], data=zip(sentences, clusters_predict))\n",
    "topic_bow = {}\n",
    "for i in range(0,visualizer.elbow_value_):\n",
    "    topic_bow[i] = set()\n",
    "    for j in data[data.topic == i]:\n",
    "        query = \"give a topic for this text in no more than 5 words: \" + j[0]\n",
    "        topic = llm(query)\n",
    "        print(topic)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "\"\"\"\n",
    "The Davies Bouldin index is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances.\n",
    "The minimum value of the DB Index is 0, whereas a smaller value (closer to 0) represents a better model that produces better clusters.\n",
    "\"\"\"\n",
    "print(f\"Davies bouldin score: {davies_bouldin_score(df_embedding_no_out,clusters_predict)}\")\n",
    "\n",
    "\"\"\"\n",
    "Calinski Harabaz Index -> Variance Ratio Criterion.\n",
    "Calinski Harabaz Index is defined as the ratio of the sum of between-cluster dispersion and of within-cluster dispersion.\n",
    "The higher the index the more separable the clusters.\n",
    "\"\"\"\n",
    "print(f\"Calinski Score: {calinski_harabasz_score(df_embedding_no_out,clusters_predict)}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The silhouette score is a metric used to calculate the goodness of fit of a clustering algorithm, but can also be used as a method for determining an optimal value of k (see here for more).\n",
    "Its value ranges from -1 to 1.\n",
    "A value of 0 indicates clusters are overlapping and either the data or the value of k is incorrect.\n",
    "1 is the ideal value and indicates that clusters are very dense and nicely separated.\n",
    "\"\"\"\n",
    "print(f\"Silhouette Score: {silhouette_score(df_embedding_no_out,clusters_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_2d(df, predict):\n",
    "\n",
    "    pca_2d_object = prince.PCA(\n",
    "    n_components=2,\n",
    "    n_iter=3,\n",
    "    rescale_with_mean=True,\n",
    "    rescale_with_std=True,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    pca_2d_object.fit(df)\n",
    "\n",
    "    df_pca_2d = pca_2d_object.transform(df)\n",
    "    df_pca_2d.columns = [\"comp1\", \"comp2\"]\n",
    "    df_pca_2d[\"cluster\"] = predict\n",
    "\n",
    "    return pca_2d_object, df_pca_2d\n",
    "\n",
    "\n",
    "\n",
    "def get_pca_3d(df, predict):\n",
    "\n",
    "    pca_3d_object = prince.PCA(\n",
    "    n_components=3,\n",
    "    n_iter=3,\n",
    "    rescale_with_mean=True,\n",
    "    rescale_with_std=True,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    pca_3d_object.fit(df)\n",
    "\n",
    "    df_pca_3d = pca_3d_object.transform(df)\n",
    "    df_pca_3d.columns = [\"comp1\", \"comp2\", \"comp3\"]\n",
    "    df_pca_3d[\"cluster\"] = predict\n",
    "\n",
    "    return pca_3d_object, df_pca_3d\n",
    "\n",
    "\n",
    "\n",
    "def plot_pca_3d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
    "\n",
    "    df = df.astype({\"cluster\": \"object\"})\n",
    "    df = df.sort_values(\"cluster\")\n",
    "\n",
    "    fig = px.scatter_3d(df, \n",
    "                        x='comp1', \n",
    "                        y='comp2', \n",
    "                        z='comp3',\n",
    "                        color='cluster',\n",
    "                        template=\"plotly\",\n",
    "                        \n",
    "                        # symbol = \"cluster\",\n",
    "                        \n",
    "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "                        title=title).update_traces(\n",
    "                            # mode = 'markers',\n",
    "                            marker={\n",
    "                                \"size\": 4,\n",
    "                                \"opacity\": opacity,\n",
    "                                # \"symbol\" : \"diamond\",\n",
    "                                \"line\": {\n",
    "                                    \"width\": width_line,\n",
    "                                    \"color\": \"black\",\n",
    "                                }\n",
    "                            }\n",
    "                        ).update_layout(\n",
    "                                width = 1000, \n",
    "                                height = 800, \n",
    "                                autosize = False, \n",
    "                                showlegend = True,\n",
    "                                legend=dict(title_font_family=\"Times New Roman\",\n",
    "                                            font=dict(size= 20)),\n",
    "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
    "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
    "                                            zaxis=dict(title = 'comp3', titlefont_color = 'black')),\n",
    "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
    "                      \n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_pca_2d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
    "\n",
    "    df = df.astype({\"cluster\": \"object\"})\n",
    "    df = df.sort_values(\"cluster\")\n",
    "\n",
    "    fig = px.scatter(df, \n",
    "                        x='comp1', \n",
    "                        y='comp2', \n",
    "                        color='cluster',\n",
    "                        template=\"plotly\",\n",
    "                        # symbol = \"cluster\",\n",
    "                        \n",
    "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "                        title=title).update_traces(\n",
    "                            # mode = 'markers',\n",
    "                            marker={\n",
    "                                \"size\": 8,\n",
    "                                \"opacity\": opacity,\n",
    "                                # \"symbol\" : \"diamond\",\n",
    "                                \"line\": {\n",
    "                                    \"width\": width_line,\n",
    "                                    \"color\": \"black\",\n",
    "                                }\n",
    "                            }\n",
    "                        ).update_layout(\n",
    "                                width = 800, \n",
    "                                height = 700, \n",
    "                                autosize = False, \n",
    "                                showlegend = True,\n",
    "                                legend=dict(title_font_family=\"Times New Roman\",\n",
    "                                            font=dict(size= 20)),\n",
    "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
    "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
    "                                            ),\n",
    "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
    "                        \n",
    "        \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3d_object, df_pca_3d = get_pca_3d(df_embedding_no_out, clusters_predict)\n",
    "plot_pca_3d(df_pca_3d, title = \"PCA Space\", opacity=1, width_line = 0.1)\n",
    "print(\"The variability is :\", pca_3d_object.eigenvalues_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d_object, df_pca_2d = get_pca_2d(df_embedding_no_out, clusters_predict)\n",
    "plot_pca_2d(df_pca_2d, title = \"PCA Space\", opacity=1, width_line = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data = df_embedding_no_out.sample(frac=0.5, replace=True, random_state=1)\n",
    "sampling_clusters = pd.DataFrame(clusters_predict).sample(frac=0.5, replace=True, random_state=1)[0].values\n",
    "\n",
    "df_tsne_3d = TSNE(\n",
    "                  n_components=3, \n",
    "                  learning_rate=500, \n",
    "                  init='random', \n",
    "                  perplexity=200, \n",
    "                  n_iter = 5000).fit_transform(sampling_data)\n",
    "\n",
    "df_tsne_3d = pd.DataFrame(df_tsne_3d, columns=[\"comp1\", \"comp2\",'comp3'])\n",
    "df_tsne_3d[\"cluster\"] = sampling_clusters\n",
    "plot_pca_3d(df_tsne_3d, title = \"T-SNE Space\", opacity=1, width_line = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_3d(df_tsne_3d, title = \"T-SNE Space\", opacity=0.1, width_line = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne_2d = TSNE(\n",
    "                  n_components=2, \n",
    "                  learning_rate=500, \n",
    "                  init='random', \n",
    "                  perplexity=200, \n",
    "                  n_iter = 5000).fit_transform(sampling_data)\n",
    "\n",
    "df_tsne_2d = pd.DataFrame(df_tsne_2d, columns=[\"comp1\", \"comp2\"])\n",
    "df_tsne_2d[\"cluster\"] = sampling_clusters\n",
    "\n",
    "plot_pca_2d(df_tsne_2d, title = \"PCA Space\", opacity=0.5, width_line = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

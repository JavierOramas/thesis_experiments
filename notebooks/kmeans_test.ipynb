{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # dataframe manipulation\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# sklearn \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import PowerTransformer, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, accuracy_score, classification_report\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "import lightgbm as lgb\n",
    "import prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "\n",
    "# # Define a function to preprocess text\n",
    "# def preprocess_text(text):\n",
    "    \n",
    "#     text = text.lower()\n",
    "#     # Split the text into sentences\n",
    "#     sentences = re.split(r'[.!?]', text)\n",
    "    \n",
    "#     for i,sentence in enumerate(sentences):\n",
    "#         sentence = sentence.split(\"|\")[-1]\n",
    "#         sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "#         sentences[i] = sentence.split(\"|\")[-1]\n",
    "    \n",
    "#     return sentences\n",
    "\n",
    "# # Load the dataset from a folder\n",
    "# dataset_folder = \"documents/topic_model_dataset\"\n",
    "# sentences = []\n",
    "\n",
    "# # Iterate over files in the dataset folder\n",
    "# for filename in os.listdir(dataset_folder):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         with open(os.path.join(dataset_folder, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "#             text = file.read()\n",
    "#             sentences.extend(preprocess_text(text))\n",
    "\n",
    "\n",
    "\n",
    "# print(f'length of documents: {len(sentences)}')\n",
    "# print(f\"first sentences:\\n\", \"\\n\".join(sentences[:5]))\n",
    "\n",
    "sentences = [\"This is a sentence about sports number \" + str(i) for i in range(1, 26)] + \\\n",
    "                 [\"This is a sentence about politics number \" + str(i) for i in range(1, 26)] + \\\n",
    "                 [\"This is a sentence about technology number \" + str(i) for i in range(1, 26)] + \\\n",
    "                 [\"This is a sentence about art number \" + str(i) for i in range(1, 26)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.embeddings.basic_embeddings import Embedding\n",
    "import pandas as pd\n",
    "\n",
    "model = Embedding().get_llm()\n",
    "\n",
    "output = model.encode(sentences=sentences,\n",
    "         show_progress_bar=True,\n",
    "         normalize_embeddings=True)\n",
    "\n",
    "df_embedding = pd.DataFrame(output)\n",
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "\n",
    "clf = ECOD()\n",
    "clf.fit(df_embedding)\n",
    "\n",
    "\n",
    "out = clf.predict(df_embedding) \n",
    "df_embedding[\"outliers\"] = out\n",
    "\n",
    "# df[\"outliers\"] = out\n",
    "\n",
    "df_embedding_no_out = df_embedding[df_embedding[\"outliers\"] == 0]\n",
    "df_embedding_no_out = df_embedding_no_out.drop([\"outliers\"], axis = 1)\n",
    "\n",
    "\n",
    "df_embedding_with_out = df_embedding.copy()\n",
    "df_embedding_with_out = df_embedding_with_out.drop([\"outliers\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_no_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "km = KMeans(init=\"k-means++\", random_state=0, n_init=\"auto\")\n",
    "visualizer = KElbowVisualizer(km, k=(2,15), locate_elbow=True)\n",
    " \n",
    "visualizer.fit(df_embedding_with_out)        # Fit the data to the visualizer\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_k = visualizer.elbow_value_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=n_k, init = \"k-means++\").fit(df_embedding_no_out)\n",
    "clusters_predict = clusters.predict(df_embedding_no_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path_or_repo_id=\"/mnt/DATA/THESIS/playground/models/mistral-7b-instruct-v0.1.Q5_K_M.gguf\",\n",
    "    model_file=\"./models/mistral-7b-instruct-v0.1.Q5_K_M.gguf\",\n",
    "    model_type=\"mistral\", \n",
    "    gpu_layers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# Download the stopwords from NLTK\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in zip(sentences,clusters_predict):\n",
    "#     print(i)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "data = pd.DataFrame(columns=[\"sentences\", \"topic\"], data=zip(sentences, clusters_predict))\n",
    "topic_bow = {}\n",
    "\n",
    "for i in data['topic'].unique():\n",
    "    # Initialize a Counter for each topic\n",
    "    topic_bow[i] = Counter()\n",
    "    for j in data[data.topic == i].sentences:\n",
    "        # Tokenize the sentence\n",
    "        words = j.split()\n",
    "        # Remove stop words and punctuation\n",
    "        words = [word for word in words if word not in stop_words and word.isalpha() and not word.startswith(\"htt\")]\n",
    "        # Add the words to the topic bag of words\n",
    "        topic_bow[i].update(words)\n",
    "\n",
    "\n",
    "    # Get the 10 most common words in the topic\n",
    "    topic_bow[i] = Counter(topic_bow[i]).most_common(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx,i in topic_bow.items():\n",
    "    text = \", \".join(j[0] for j in i)\n",
    "    print(text)\n",
    "\n",
    "    topic = llm(f\"\"\"\n",
    "                    You will be given some words and you should create a topic name to match those words. only write the topic name \n",
    "                        Example 1:\n",
    "                            text: PC, laptop, monitor, AI, internet.\n",
    "                            topic: tech.\n",
    "                        \n",
    "                        Example 2:\n",
    "                            text: hospital, aspirin, blood, injection, doctor\n",
    "                            topic: Medicine.\n",
    "                        \n",
    "                        Generate in single word: \n",
    "                            text: {text},\n",
    "                            topic:\n",
    "                        \"\"\", temperature=0)\n",
    "    print(\">\", topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "\"\"\"\n",
    "The Davies Bouldin index is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances.\n",
    "The minimum value of the DB Index is 0, whereas a smaller value (closer to 0) represents a better model that produces better clusters.\n",
    "\"\"\"\n",
    "print(f\"Davies bouldin score: {davies_bouldin_score(df_embedding_no_out,clusters_predict)}\")\n",
    "\n",
    "\"\"\"\n",
    "Calinski Harabaz Index -> Variance Ratio Criterion.\n",
    "Calinski Harabaz Index is defined as the ratio of the sum of between-cluster dispersion and of within-cluster dispersion.\n",
    "The higher the index the more separable the clusters.\n",
    "\"\"\"\n",
    "print(f\"Calinski Score: {calinski_harabasz_score(df_embedding_no_out,clusters_predict)}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The silhouette score is a metric used to calculate the goodness of fit of a clustering algorithm, but can also be used as a method for determining an optimal value of k (see here for more).\n",
    "Its value ranges from -1 to 1.\n",
    "A value of 0 indicates clusters are overlapping and either the data or the value of k is incorrect.\n",
    "1 is the ideal value and indicates that clusters are very dense and nicely separated.\n",
    "\"\"\"\n",
    "print(f\"Silhouette Score: {silhouette_score(df_embedding_no_out,clusters_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_2d(df, predict):\n",
    "\n",
    "    pca_2d_object = prince.PCA(\n",
    "    n_components=2,\n",
    "    n_iter=3,\n",
    "    rescale_with_mean=True,\n",
    "    rescale_with_std=True,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    pca_2d_object.fit(df)\n",
    "\n",
    "    df_pca_2d = pca_2d_object.transform(df)\n",
    "    df_pca_2d.columns = [\"comp1\", \"comp2\"]\n",
    "    df_pca_2d[\"cluster\"] = predict\n",
    "\n",
    "    return pca_2d_object, df_pca_2d\n",
    "\n",
    "\n",
    "\n",
    "def get_pca_3d(df, predict):\n",
    "\n",
    "    pca_3d_object = prince.PCA(\n",
    "    n_components=3,\n",
    "    n_iter=3,\n",
    "    rescale_with_mean=True,\n",
    "    rescale_with_std=True,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    pca_3d_object.fit(df)\n",
    "\n",
    "    df_pca_3d = pca_3d_object.transform(df)\n",
    "    df_pca_3d.columns = [\"comp1\", \"comp2\", \"comp3\"]\n",
    "    df_pca_3d[\"cluster\"] = predict\n",
    "\n",
    "    return pca_3d_object, df_pca_3d\n",
    "\n",
    "\n",
    "\n",
    "def plot_pca_3d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
    "\n",
    "    df = df.astype({\"cluster\": \"object\"})\n",
    "    df = df.sort_values(\"cluster\")\n",
    "\n",
    "    fig = px.scatter_3d(df, \n",
    "                        x='comp1', \n",
    "                        y='comp2', \n",
    "                        z='comp3',\n",
    "                        color='cluster',\n",
    "                        template=\"plotly\",\n",
    "                        \n",
    "                        # symbol = \"cluster\",\n",
    "                        \n",
    "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "                        title=title).update_traces(\n",
    "                            # mode = 'markers',\n",
    "                            marker={\n",
    "                                \"size\": 4,\n",
    "                                \"opacity\": opacity,\n",
    "                                # \"symbol\" : \"diamond\",\n",
    "                                \"line\": {\n",
    "                                    \"width\": width_line,\n",
    "                                    \"color\": \"black\",\n",
    "                                }\n",
    "                            }\n",
    "                        ).update_layout(\n",
    "                                width = 1000, \n",
    "                                height = 800, \n",
    "                                autosize = False, \n",
    "                                showlegend = True,\n",
    "                                legend=dict(title_font_family=\"Times New Roman\",\n",
    "                                            font=dict(size= 20)),\n",
    "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
    "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
    "                                            zaxis=dict(title = 'comp3', titlefont_color = 'black')),\n",
    "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
    "                      \n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_pca_2d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
    "\n",
    "    df = df.astype({\"cluster\": \"object\"})\n",
    "    df = df.sort_values(\"cluster\")\n",
    "\n",
    "    fig = px.scatter(df, \n",
    "                        x='comp1', \n",
    "                        y='comp2', \n",
    "                        color='cluster',\n",
    "                        template=\"plotly\",\n",
    "                        # symbol = \"cluster\",\n",
    "                        \n",
    "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "                        title=title).update_traces(\n",
    "                            # mode = 'markers',\n",
    "                            marker={\n",
    "                                \"size\": 8,\n",
    "                                \"opacity\": opacity,\n",
    "                                # \"symbol\" : \"diamond\",\n",
    "                                \"line\": {\n",
    "                                    \"width\": width_line,\n",
    "                                    \"color\": \"black\",\n",
    "                                }\n",
    "                            }\n",
    "                        ).update_layout(\n",
    "                                width = 800, \n",
    "                                height = 700, \n",
    "                                autosize = False, \n",
    "                                showlegend = True,\n",
    "                                legend=dict(title_font_family=\"Times New Roman\",\n",
    "                                            font=dict(size= 20)),\n",
    "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
    "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
    "                                            ),\n",
    "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
    "                        \n",
    "        \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3d_object, df_pca_3d = get_pca_3d(df_embedding_no_out, clusters_predict)\n",
    "plot_pca_3d(df_pca_3d, title = \"PCA Space\", opacity=1, width_line = 0.1)\n",
    "print(\"The variability is :\", pca_3d_object.eigenvalues_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d_object, df_pca_2d = get_pca_2d(df_embedding_no_out, clusters_predict)\n",
    "plot_pca_2d(df_pca_2d, title = \"PCA Space\", opacity=1, width_line = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data = df_embedding_no_out.sample(frac=0.5, replace=True, random_state=1)\n",
    "sampling_clusters = pd.DataFrame(clusters_predict).sample(frac=0.5, replace=True, random_state=1)[0].values\n",
    "\n",
    "df_tsne_3d = TSNE(\n",
    "                  n_components=3, \n",
    "                  learning_rate=500, \n",
    "                  init='random', \n",
    "                  perplexity=200, \n",
    "                  n_iter = 5000).fit_transform(sampling_data)\n",
    "\n",
    "df_tsne_3d = pd.DataFrame(df_tsne_3d, columns=[\"comp1\", \"comp2\",'comp3'])\n",
    "df_tsne_3d[\"cluster\"] = sampling_clusters\n",
    "plot_pca_3d(df_tsne_3d, title = \"T-SNE Space\", opacity=1, width_line = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_3d(df_tsne_3d, title = \"T-SNE Space\", opacity=0.1, width_line = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne_2d = TSNE(\n",
    "                  n_components=2, \n",
    "                  learning_rate=500, \n",
    "                  init='random', \n",
    "                  perplexity=200, \n",
    "                  n_iter = 5000).fit_transform(sampling_data)\n",
    "\n",
    "df_tsne_2d = pd.DataFrame(df_tsne_2d, columns=[\"comp1\", \"comp2\"])\n",
    "df_tsne_2d[\"cluster\"] = sampling_clusters\n",
    "\n",
    "plot_pca_2d(df_tsne_2d, title = \"PCA Space\", opacity=0.5, width_line = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

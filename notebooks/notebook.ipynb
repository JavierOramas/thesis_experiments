{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c28486e28bc49adba34d209cf57cc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f487e2e4b9774de492dc82922f9ce330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9fb2d7be334015bdf9b615180f3dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52068b024d32487e8d4b0f017cfb651c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be6d9fcc6a74b15becfdf26e1505f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/67.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628c8be837e84516abe7fbd9a6807d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c17a165ed64d2fb334e05be307b0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac419be3cfc419a82bcbc31261c13c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating ca_test split:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292024aa0b9643a39250c1ee3044bdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd3063f03964a00aa0e55097a2c1ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09704895e27472ab6556041ab8d559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24d3d8ca92743a4af4f559c4b098bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ce13602d6145b2a7b8b9cbcc107ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id=None)}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each prediction\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_aggregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (f1),\n",
       "    rouge2: rouge_2 (f1),\n",
       "    rougeL: rouge_l (f1),\n",
       "    rougeLsum: rouge_lsum (f1)\n",
       "Examples:\n",
       "\n",
       "    >>> rouge = evaluate.load('rouge')\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#     result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "#     result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "#     return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_billsum_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9348ac35e85f461bad225182b9699e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a4c1e3d46c481b9696b9aa2c8c8c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2aecfc32f54075bbf506cd15b61b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5064d761b74b4fdfa5d4e2e3621bb3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9ec68e8dec45b59841e2446b15031e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"the Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country.\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"stevhliu/my_awesome_billsum_model\")\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[21603,\n",
       "  10,\n",
       "  37,\n",
       "  86,\n",
       "  89,\n",
       "  6105,\n",
       "  419,\n",
       "  8291,\n",
       "  1983,\n",
       "  1364,\n",
       "  7,\n",
       "  7744,\n",
       "  2672,\n",
       "  1358,\n",
       "  6,\n",
       "  533,\n",
       "  124,\n",
       "  1358,\n",
       "  6,\n",
       "  11,\n",
       "  827,\n",
       "  1358,\n",
       "  5,\n",
       "  94,\n",
       "  31,\n",
       "  7,\n",
       "  8,\n",
       "  167,\n",
       "  8299,\n",
       "  1041,\n",
       "  30,\n",
       "  3,\n",
       "  26074,\n",
       "  8,\n",
       "  3298,\n",
       "  5362,\n",
       "  16,\n",
       "  797,\n",
       "  892,\n",
       "  6,\n",
       "  84,\n",
       "  56,\n",
       "  5656,\n",
       "  95,\n",
       "  797,\n",
       "  2765,\n",
       "  11,\n",
       "  482,\n",
       "  207,\n",
       "  18,\n",
       "  8832,\n",
       "  53,\n",
       "  6,\n",
       "  7021,\n",
       "  2476,\n",
       "  640,\n",
       "  8,\n",
       "  684,\n",
       "  5,\n",
       "  94,\n",
       "  31,\n",
       "  195,\n",
       "  1364,\n",
       "  8,\n",
       "  11724,\n",
       "  11,\n",
       "  987,\n",
       "  8,\n",
       "  6173,\n",
       "  18,\n",
       "  1123,\n",
       "  138,\n",
       "  189,\n",
       "  63,\n",
       "  11,\n",
       "  11711,\n",
       "  12,\n",
       "  726,\n",
       "  70,\n",
       "  2725,\n",
       "  698,\n",
       "  5,\n",
       "  275,\n",
       "  150,\n",
       "  80,\n",
       "  492,\n",
       "  365,\n",
       "  1514,\n",
       "  31471,\n",
       "  399,\n",
       "  215,\n",
       "  56,\n",
       "  726,\n",
       "  3,\n",
       "  9,\n",
       "  23925,\n",
       "  72,\n",
       "  16,\n",
       "  5161,\n",
       "  5,\n",
       "  1]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/my_awesome_billsum_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "inputs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "vectors = np.random.rand(100, 100)\n",
    "client.upsert(\n",
    "    collection_name=\"my_collection\",\n",
    "    points=[\n",
    "        PointStruct(\n",
    "            id=idx,\n",
    "            vector=vector.tolist(),\n",
    "            payload={\"color\": \"red\", \"rand_number\": idx % 10}\n",
    "        )\n",
    "        for idx, vector in enumerate(vectors)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from llama_index import GPTQdrantIndex\n",
    "\n",
    "import qdrant_client\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    \"localhost:6333\",\n",
    "    api_key=None, # For Qdrant Cloud, None for local instance\n",
    ")\n",
    "\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=\"my_collection\",\n",
    "    vectors_config=VectorParams(size=100, distance=Distance.COSINE),\n",
    ")\n",
    "# index = GPTQdrantIndex.from_documents(documents, client=client, collection_name=\"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Format error in JSON body: unknown variant `id`, expected `batch` or `points` at line 1 column 5\"},\"time\":0.0}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mqdrant_client\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m PointStruct\n\u001b[0;32m----> 4\u001b[0m client\u001b[39m.\u001b[39;49mupsert(\n\u001b[1;32m      5\u001b[0m     collection_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmy_collection\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     points\u001b[39m=\u001b[39;49mPointStruct(\n\u001b[1;32m      7\u001b[0m             \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m             vector\u001b[39m=\u001b[39;49m[ i \u001b[39m*\u001b[39;49m \u001b[39m1.0\u001b[39;49m \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m inputs\u001b[39m.\u001b[39;49mtolist()[\u001b[39m0\u001b[39;49m] ],\n\u001b[1;32m      9\u001b[0m             payload\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mcolor\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrand_number\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m111\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39m10\u001b[39;49m}\n\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m     \n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/qdrant_client/qdrant_client.py:747\u001b[0m, in \u001b[0;36mQdrantClient.upsert\u001b[0;34m(self, collection_name, points, wait, ordering, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update or insert a new point into the collection.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \n\u001b[1;32m    725\u001b[0m \u001b[39mIf point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39m    Operation result\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(kwargs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown arguments: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 747\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mupsert(\n\u001b[1;32m    748\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    749\u001b[0m     points\u001b[39m=\u001b[39;49mpoints,\n\u001b[1;32m    750\u001b[0m     wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m    751\u001b[0m     ordering\u001b[39m=\u001b[39;49mordering,\n\u001b[1;32m    752\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    753\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/qdrant_client/qdrant_remote.py:1088\u001b[0m, in \u001b[0;36mQdrantRemote.upsert\u001b[0;34m(self, collection_name, points, wait, ordering, **kwargs)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(points, rest_models\u001b[39m.\u001b[39mBatch):\n\u001b[1;32m   1086\u001b[0m     points \u001b[39m=\u001b[39m rest_models\u001b[39m.\u001b[39mPointsBatch(batch\u001b[39m=\u001b[39mpoints)\n\u001b[0;32m-> 1088\u001b[0m http_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopenapi_client\u001b[39m.\u001b[39;49mpoints_api\u001b[39m.\u001b[39;49mupsert_points(\n\u001b[1;32m   1089\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m   1090\u001b[0m     wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m   1091\u001b[0m     point_insert_operations\u001b[39m=\u001b[39;49mpoints,\n\u001b[1;32m   1092\u001b[0m     ordering\u001b[39m=\u001b[39;49mordering,\n\u001b[1;32m   1093\u001b[0m )\u001b[39m.\u001b[39mresult\n\u001b[1;32m   1094\u001b[0m \u001b[39massert\u001b[39;00m http_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mUpsert returned None result\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1095\u001b[0m \u001b[39mreturn\u001b[39;00m http_result\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/qdrant_client/http/api/points_api.py:1160\u001b[0m, in \u001b[0;36mSyncPointsApi.upsert_points\u001b[0;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupsert_points\u001b[39m(\n\u001b[1;32m   1151\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1152\u001b[0m     collection_name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     point_insert_operations: m\u001b[39m.\u001b[39mPointInsertOperations \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m m\u001b[39m.\u001b[39mInlineResponse2006:\n\u001b[1;32m   1157\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_for_upsert_points(\n\u001b[1;32m   1161\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m   1162\u001b[0m         wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m   1163\u001b[0m         ordering\u001b[39m=\u001b[39;49mordering,\n\u001b[1;32m   1164\u001b[0m         point_insert_operations\u001b[39m=\u001b[39;49mpoint_insert_operations,\n\u001b[1;32m   1165\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/qdrant_client/http/api/points_api.py:586\u001b[0m, in \u001b[0;36m_PointsApi._build_for_upsert_points\u001b[0;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m headers:\n\u001b[1;32m    585\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 586\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    587\u001b[0m     type_\u001b[39m=\u001b[39;49mm\u001b[39m.\u001b[39;49mInlineResponse2006,\n\u001b[1;32m    588\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    589\u001b[0m     url\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/collections/\u001b[39;49m\u001b[39m{collection_name}\u001b[39;49;00m\u001b[39m/points\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    590\u001b[0m     path_params\u001b[39m=\u001b[39;49mpath_params,\n\u001b[1;32m    591\u001b[0m     params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    592\u001b[0m     data\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    593\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/qdrant_client/http/api_client.py:68\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m url \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m url\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpath_params)\n\u001b[1;32m     67\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mbuild_request(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(request, type_)\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/qdrant_client/http/api_client.py:91\u001b[0m, in \u001b[0;36mApiClient.send\u001b[0;34m(self, request, type_)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[39mexcept\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m         \u001b[39mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[0;32m---> 91\u001b[0m \u001b[39mraise\u001b[39;00m UnexpectedResponse\u001b[39m.\u001b[39mfor_response(response)\n",
      "\u001b[0;31mUnexpectedResponse\u001b[0m: Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Format error in JSON body: unknown variant `id`, expected `batch` or `points` at line 1 column 5\"},\"time\":0.0}'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=\"my_collection\",\n",
    "    points=PointStruct(\n",
    "            id=1000,\n",
    "            vector=[ i * 1.0 for i in inputs.tolist()[0] ],\n",
    "            payload={\"color\": \"red\", \"rand_number\": 111 % 10}\n",
    "        )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     8,    16,    89,  6105,  4709,  2876,    92,   704,    72,\n",
       "          1645,    21,     8,     3,    23,    52,     9,  4703,    12,  1428,\n",
       "          7744,  4845,     3,     5,    34,  1428,     7,  7744,  2672,  1358,\n",
       "             6,   533,   124,  1358,     6,  5347,  1358,     6,    11,   827,\n",
       "          1358,     3,     5,     8,   973,   133,  3033,    95, 10211,  2765,\n",
       "            11,   482,   207,    18,  8832,    53,  2476,   640,     8,   684,\n",
       "             3,     5,     1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"stevhliu/my_awesome_billsum_model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=200, do_sample=True)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the inflation reduction bill also offers more opportunities for the iracial to reduce prescription drugs. it reduces prescription drug costs, health care costs, labor costs, and energy costs. the law would raise up american workers and create good-paying jobs across the country.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: einops in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (0.6.1)\n",
      "Requirement already satisfied: transformers in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (4.22.0.dev0)\n",
      "Requirement already satisfied: accelerate in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.27.0)\n",
      "Requirement already satisfied: lit in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: psutil in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: fsspec in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: accelerate in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from accelerate) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.0)\n",
      "Requirement already satisfied: lit in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch einops transformers accelerate\n",
    "! pip install accelerate\n",
    "# ! pip install --upgrade torch\n",
    "# ! pip install request==\"2.27.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaModel, LlamaConfig\n",
    "\n",
    "# Initializing a LLaMA llama-7b style configuration\n",
    "configuration = LlamaConfig()\n",
    "\n",
    "# Initializing a model from the llama-7b style configuration\n",
    "model = LlamaModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/joramas/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "# model_id=\"impira/layoutlm-document-qa\"\n",
    "model_id=\"tiiuae/falcon-7b\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id)\n",
    "model=AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not load model impira/layoutlm-document-qa with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForDocumentQuestionAnswering'>, <class 'transformers.models.layoutlm.modeling_layoutlm.LayoutLMForQuestionAnswering'>).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 3\u001b[0m nlp \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mdocument-question-answering\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mimpira/layoutlm-document-qa\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m nlp(\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://templates.invoicehome.com/invoice-template-us-neat-750px.png\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWhat is the invoice number?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39m# {'score': 0.9943977, 'answer': 'us-001', 'start': 15, 'end': 15}\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/pipelines/__init__.py:788\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 788\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    789\u001b[0m         model,\n\u001b[1;32m    790\u001b[0m         model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    791\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    792\u001b[0m         framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    793\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    794\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    795\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    796\u001b[0m     )\n\u001b[1;32m    798\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    799\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/pipelines/base.py:278\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 278\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     framework \u001b[39m=\u001b[39m infer_framework(model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model impira/layoutlm-document-qa with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForDocumentQuestionAnswering'>, <class 'transformers.models.layoutlm.modeling_layoutlm.LayoutLMForQuestionAnswering'>)."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"document-question-answering\",\n",
    "    model=\"impira/layoutlm-document-qa\",\n",
    ")\n",
    "\n",
    "nlp(\n",
    "    \"https://templates.invoicehome.com/invoice-template-us-neat-750px.png\",\n",
    "    \"What is the invoice number?\"\n",
    ")\n",
    "# {'score': 0.9943977, 'answer': 'us-001', 'start': 15, 'end': 15}\n",
    "\n",
    "nlp(\n",
    "    \"https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\",\n",
    "    \"What is the purchase amount?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f588cd07e3454dc19ad594e0d96e723e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SSLError",
     "evalue": "(MaxRetryError(\"HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /repos/80/bd/80bd1e4a99ab55602d887f91215879d76ac3e1b877b8f683477be2952b8cb778/1c4b989693576ce79edf5f8f1a2d199d66c1448d35a126e52ba09cb67ca5da39?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00001-of-00002.bin%3B+filename%3D%22pytorch_model-00001-of-00002.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1690739196&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDczOTE5Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84MC9iZC84MGJkMWU0YTk5YWI1NTYwMmQ4ODdmOTEyMTU4NzlkNzZhYzNlMWI4NzdiOGY2ODM0NzdiZTI5NTJiOGNiNzc4LzFjNGI5ODk2OTM1NzZjZTc5ZWRmNWY4ZjFhMmQxOTlkNjZjMTQ0OGQzNWExMjZlNTJiYTA5Y2I2N2NhNWRhMzk~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=yomeOAoycyBIWKChMcdkPMkRNhytdCIu1m6GtSVCQvdcfmYSyXqq5i9kP5hf0PSgGfMtmXBSX5Ca82K9RnzImPM7zLlx~sb-g4x1Ftzz4haRrH8ajz-Sdq2tSLt87WTdIHVgXpemos13Ycn1wqTFiQtiPywFepGQViuc8jNKc9KCx1VL2OYzFO29g5p8-JN7UCeCCjgvL237qNAYeHLU1cl4vXzFUYql7g5EPfNq1oQj2FYVUzQbKWMIJGy-Jyt4TU~vdDe~ZJll7UkrbeI4Fny4s3aZziHodAMHQwR5TFTBa7pVvBdTRHo8zIpXOOZQ-BXnpfCJ3g7Wl8FRjRwwPA__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate is not yet valid (_ssl.c:1129)')))\"), '(Request ID: 85494905-a408-472c-9aa6-0cd36f22f605)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[0;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[1;32m    420\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[1;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[1;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[1;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[1;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[1;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[1;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[1;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[1;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/util/ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[0;32m--> 449\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[1;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39;49mserver_hostname\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/util/ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n\u001b[1;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/ssl.py:501\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    498\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    499\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    502\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    503\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    504\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    505\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    506\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    507\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    508\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    509\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1041\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1042\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/ssl.py:1310\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1310\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1311\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate is not yet valid (_ssl.c:1129)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    796\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 798\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    799\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    801\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /repos/80/bd/80bd1e4a99ab55602d887f91215879d76ac3e1b877b8f683477be2952b8cb778/1c4b989693576ce79edf5f8f1a2d199d66c1448d35a126e52ba09cb67ca5da39?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00001-of-00002.bin%3B+filename%3D%22pytorch_model-00001-of-00002.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1690739196&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDczOTE5Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84MC9iZC84MGJkMWU0YTk5YWI1NTYwMmQ4ODdmOTEyMTU4NzlkNzZhYzNlMWI4NzdiOGY2ODM0NzdiZTI5NTJiOGNiNzc4LzFjNGI5ODk2OTM1NzZjZTc5ZWRmNWY4ZjFhMmQxOTlkNjZjMTQ0OGQzNWExMjZlNTJiYTA5Y2I2N2NhNWRhMzk~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=yomeOAoycyBIWKChMcdkPMkRNhytdCIu1m6GtSVCQvdcfmYSyXqq5i9kP5hf0PSgGfMtmXBSX5Ca82K9RnzImPM7zLlx~sb-g4x1Ftzz4haRrH8ajz-Sdq2tSLt87WTdIHVgXpemos13Ycn1wqTFiQtiPywFepGQViuc8jNKc9KCx1VL2OYzFO29g5p8-JN7UCeCCjgvL237qNAYeHLU1cl4vXzFUYql7g5EPfNq1oQj2FYVUzQbKWMIJGy-Jyt4TU~vdDe~ZJll7UkrbeI4Fny4s3aZziHodAMHQwR5TFTBa7pVvBdTRHo8zIpXOOZQ-BXnpfCJ3g7Wl8FRjRwwPA__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate is not yet valid (_ssl.c:1129)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model_id\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtiiuae/falcon-7b\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m tokenizer\u001b[39m=\u001b[39mAutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m----> 7\u001b[0m model\u001b[39m=\u001b[39mAutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_id, trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      9\u001b[0m sequences \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m     10\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mGirafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mDaniel: Hello, Girafatron!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mGirafatron:\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     max_length\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     eos_token_id\u001b[39m=\u001b[39mtokenizer\u001b[39m.\u001b[39meos_token_id,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m sequences:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:488\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mregister(config\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, model_class, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    489\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/modeling_utils.py:2610\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2607\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[1;32m   2609\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 2610\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   2611\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2612\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2613\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2614\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2615\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2616\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2617\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2618\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2619\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   2620\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2621\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2622\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   2623\u001b[0m     )\n\u001b[1;32m   2625\u001b[0m \u001b[39m# load pt weights early so that we know which dtype to init the model under\u001b[39;00m\n\u001b[1;32m   2626\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/utils/hub.py:958\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token, user_agent, revision, subfolder, _commit_hash)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    956\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[0;32m--> 958\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    959\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m    960\u001b[0m             shard_filename,\n\u001b[1;32m    961\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    962\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    963\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    964\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    965\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    966\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    967\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    968\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    969\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    970\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49m_commit_hash,\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    972\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    414\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[1;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/huggingface_hub/file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[1;32m   1362\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[0;32m-> 1364\u001b[0m     http_get(\n\u001b[1;32m   1365\u001b[0m         url_to_download,\n\u001b[1;32m   1366\u001b[0m         temp_file,\n\u001b[1;32m   1367\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1368\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m   1369\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1370\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[1;32m   1371\u001b[0m     )\n\u001b[1;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/huggingface_hub/file_download.py:505\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m resume_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    503\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mRange\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbytes=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (resume_size,)\n\u001b[0;32m--> 505\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m    506\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    507\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    508\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    509\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    510\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    511\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    512\u001b[0m     max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    513\u001b[0m )\n\u001b[1;32m    514\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m    515\u001b[0m content_length \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Length\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/huggingface_hub/file_download.py:442\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[1;32m    441\u001b[0m \u001b[39m# 3. Exponential backoff\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m \u001b[39mreturn\u001b[39;00m http_backoff(\n\u001b[1;32m    443\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    444\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    445\u001b[0m     max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    446\u001b[0m     base_wait_time\u001b[39m=\u001b[39;49mbase_wait_time,\n\u001b[1;32m    447\u001b[0m     max_wait_time\u001b[39m=\u001b[39;49mmax_wait_time,\n\u001b[1;32m    448\u001b[0m     retry_on_exceptions\u001b[39m=\u001b[39;49m(Timeout, ProxyError),\n\u001b[1;32m    449\u001b[0m     retry_on_status_codes\u001b[39m=\u001b[39;49m(),\n\u001b[1;32m    450\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    451\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    452\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:258\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/requests/adapters.py:517\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mSSLError\u001b[0m: (MaxRetryError(\"HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /repos/80/bd/80bd1e4a99ab55602d887f91215879d76ac3e1b877b8f683477be2952b8cb778/1c4b989693576ce79edf5f8f1a2d199d66c1448d35a126e52ba09cb67ca5da39?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00001-of-00002.bin%3B+filename%3D%22pytorch_model-00001-of-00002.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1690739196&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDczOTE5Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84MC9iZC84MGJkMWU0YTk5YWI1NTYwMmQ4ODdmOTEyMTU4NzlkNzZhYzNlMWI4NzdiOGY2ODM0NzdiZTI5NTJiOGNiNzc4LzFjNGI5ODk2OTM1NzZjZTc5ZWRmNWY4ZjFhMmQxOTlkNjZjMTQ0OGQzNWExMjZlNTJiYTA5Y2I2N2NhNWRhMzk~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=yomeOAoycyBIWKChMcdkPMkRNhytdCIu1m6GtSVCQvdcfmYSyXqq5i9kP5hf0PSgGfMtmXBSX5Ca82K9RnzImPM7zLlx~sb-g4x1Ftzz4haRrH8ajz-Sdq2tSLt87WTdIHVgXpemos13Ycn1wqTFiQtiPywFepGQViuc8jNKc9KCx1VL2OYzFO29g5p8-JN7UCeCCjgvL237qNAYeHLU1cl4vXzFUYql7g5EPfNq1oQj2FYVUzQbKWMIJGy-Jyt4TU~vdDe~ZJll7UkrbeI4Fny4s3aZziHodAMHQwR5TFTBa7pVvBdTRHo8zIpXOOZQ-BXnpfCJ3g7Wl8FRjRwwPA__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate is not yet valid (_ssl.c:1129)')))\"), '(Request ID: 85494905-a408-472c-9aa6-0cd36f22f605)')"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sequences = pipeline(\n",
    "   \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequences = pipeline(\n",
    "   \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not load model gpt2 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline, set_seed\n\u001b[0;32m----> 2\u001b[0m generator \u001b[39m=\u001b[39m pipeline(\u001b[39m'\u001b[39;49m\u001b[39mtext-generation\u001b[39;49m\u001b[39m'\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpt2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m set_seed(\u001b[39m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m generator(\u001b[39m\"\u001b[39m\u001b[39mHello, I\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm a language model,\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, num_return_sequences\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/pipelines/__init__.py:702\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[39m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \u001b[39m# Will load the correct model if possible\u001b[39;00m\n\u001b[1;32m    701\u001b[0m model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 702\u001b[0m framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    703\u001b[0m     model,\n\u001b[1;32m    704\u001b[0m     model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    705\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    706\u001b[0m     framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    707\u001b[0m     task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    708\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    709\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    710\u001b[0m )\n\u001b[1;32m    712\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    713\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/miniconda/envs/thesis/lib/python3.9/site-packages/transformers/pipelines/base.py:266\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m framework \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mTF\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m \u001b[39mreturn\u001b[39;00m framework, model\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model gpt2 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>)."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
